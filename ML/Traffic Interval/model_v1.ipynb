{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and sort them by time\n",
    "df = pd.read_csv(\"./Data/traffic.csv\")\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.sort_values(by=['DateTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Junction as a numerical feature\n",
    "junction_encoder = LabelEncoder()\n",
    "df['Junction_encoded'] = junction_encoder.fit_transform(df['Junction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-based features for better pattern recognization\n",
    "df['Hour'] = df['DateTime'].dt.hour\n",
    "df['DayOfWeek'] = df['DateTime'].dt.dayofweek\n",
    "df['Month'] = df['DateTime'].dt.month\n",
    "df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "scaler_dict = {}\n",
    "numerical_features = ['Vehicles', 'Hour', 'DayOfWeek', 'Month', 'Junction_encoded']\n",
    "for feature in numerical_features:\n",
    "    scaler = MinMaxScaler()\n",
    "    df[f'{feature}_normalized'] = scaler.fit_transform(df[[feature]])\n",
    "    scaler_dict[feature] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model with multi-step prediction\n",
    "class JunctionTrafficLSTM(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=32, num_layers=5, output_size=1):\n",
    "        super(JunctionTrafficLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x, future_steps=1, teacher_forcing_ratio=0.5):\n",
    "        batch_size = x.size(0)\n",
    "        outputs = []\n",
    "        lstm_out, (h, c) = self.lstm(x)\n",
    "        decoder_input = x[:, -1:, :]\n",
    "        \n",
    "        for i in range(future_steps):\n",
    "            # Run LSTM step\n",
    "            out, (h, c) = self.lstm(decoder_input, (h, c))\n",
    "            \n",
    "            # Process through\n",
    "            features = self.dropout(out[:, -1])\n",
    "            features = self.relu(self.fc1(features))\n",
    "            features = self.relu(self.fc2(features))\n",
    "            prediction = self.fc3(features)\n",
    "            \n",
    "            outputs.append(prediction)\n",
    "        \n",
    "            if self.training and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                decoder_input = x[:, i+1:i+2, :] if i+1 < x.size(1) else decoder_input\n",
    "            else:\n",
    "                next_input = decoder_input.clone()\n",
    "                next_input[:, 0, 0] = prediction.squeeze()\n",
    "                decoder_input = next_input\n",
    "        \n",
    "        return torch.stack(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multistep_sequences(data, input_seq_length, prediction_length):\n",
    "    feature_cols = [col for col in data.columns if '_normalized' in col]\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for junction in data['Junction'].unique():\n",
    "        junction_data = data[data['Junction'] == junction].copy()\n",
    "        \n",
    "        for i in range(len(junction_data) - input_seq_length - prediction_length):\n",
    "            # Input\n",
    "            seq = junction_data[feature_cols].iloc[i:i+input_seq_length].values\n",
    "            \n",
    "            # Target\n",
    "            target = junction_data['Vehicles_normalized'].iloc[i+input_seq_length:i+input_seq_length+prediction_length].values\n",
    "            \n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multistep_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=10, prediction_length=24):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Generate predictions\n",
    "            outputs = model(batch_X, future_steps=prediction_length)\n",
    "            \n",
    "            # Ensure outputs and batch_y have the same shape\n",
    "            outputs = outputs.squeeze()\n",
    "            if len(outputs.shape) == 1:\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            if len(batch_y.shape) == 1:\n",
    "                batch_y = batch_y.unsqueeze(0)\n",
    "\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            if outputs.size(1) > 1:\n",
    "                output_diff = outputs[:, 1:] - outputs[:, :-1]\n",
    "                target_diff = batch_y[:, 1:] - batch_y[:, :-1]\n",
    "                \n",
    "                min_length = min(output_diff.size(1), target_diff.size(1))\n",
    "                consistency_loss = criterion(\n",
    "                    output_diff[:, :min_length],\n",
    "                    target_diff[:, :min_length]\n",
    "                )\n",
    "                loss = loss + 0.1 * consistency_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X, future_steps=prediction_length)\n",
    "                \n",
    "                outputs = outputs.squeeze()\n",
    "                if len(outputs.shape) == 1:\n",
    "                    outputs = outputs.unsqueeze(0)\n",
    "                if len(batch_y.shape) == 1:\n",
    "                    batch_y = batch_y.unsqueeze(0)\n",
    "                    \n",
    "                val_loss += criterion(outputs, batch_y).item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_loader, threshold, prediction_length=24):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X, future_steps=prediction_length)\n",
    "            difference = torch.abs(outputs.squeeze() - batch_y)\n",
    "            correct += (difference <= threshold).sum().item()\n",
    "            total += batch_y.numel()\n",
    "    \n",
    "    accuracy_percentage = (correct / total) * 100\n",
    "    print(f\"Test Accuracy: {accuracy_percentage:.2f}%\")\n",
    "    return accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_traffic(model, latest_time, num_hours, scalers, seq_length=10):\n",
    "    model.eval()\n",
    "    closest_time_idx = (df['DateTime'] - latest_time).abs().argmin()\n",
    "    print((df['DateTime'] - latest_time).abs().min())\n",
    "\n",
    "    feature_cols = [col for col in df.columns if '_normalized' in col]\n",
    "    input_seq = df.iloc[closest_time_idx:closest_time_idx+seq_length][feature_cols].values\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_seq, future_steps=num_hours)\n",
    "        predictions = predictions.squeeze().cpu().numpy()\n",
    "\n",
    "    # Inverse transform \n",
    "    predictions = scalers['Vehicles'].inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seq_length = 10\n",
    "prediction_length = 24  # 24 hours ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_multistep_sequences(df, seq_length, prediction_length)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "val_size = int(0.1 * len(X_train))\n",
    "X_val = X_train[-val_size:]\n",
    "y_val = y_train[-val_size:]\n",
    "X_train = X_train[:-val_size]\n",
    "y_train = y_train[:-val_size]\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JunctionTrafficLSTM().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0052, Val Loss: 0.0038\n",
      "Epoch 2, Train Loss: 0.0019, Val Loss: 0.0025\n",
      "Epoch 3, Train Loss: 0.0013, Val Loss: 0.0023\n",
      "Epoch 4, Train Loss: 0.0011, Val Loss: 0.0024\n",
      "Epoch 5, Train Loss: 0.0010, Val Loss: 0.0024\n",
      "Epoch 6, Train Loss: 0.0010, Val Loss: 0.0022\n",
      "Epoch 7, Train Loss: 0.0009, Val Loss: 0.0021\n",
      "Epoch 8, Train Loss: 0.0009, Val Loss: 0.0021\n",
      "Epoch 9, Train Loss: 0.0008, Val Loss: 0.0021\n",
      "Epoch 10, Train Loss: 0.0008, Val Loss: 0.0020\n",
      "Epoch 11, Train Loss: 0.0008, Val Loss: 0.0023\n",
      "Epoch 12, Train Loss: 0.0007, Val Loss: 0.0021\n",
      "Epoch 13, Train Loss: 0.0007, Val Loss: 0.0022\n",
      "Epoch 14, Train Loss: 0.0007, Val Loss: 0.0020\n",
      "Epoch 15, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 16, Train Loss: 0.0006, Val Loss: 0.0021\n",
      "Epoch 17, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 18, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 19, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 20, Train Loss: 0.0006, Val Loss: 0.0019\n",
      "Epoch 21, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 22, Train Loss: 0.0006, Val Loss: 0.0019\n",
      "Epoch 23, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 24, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 25, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 26, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 27, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 28, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 29, Train Loss: 0.0006, Val Loss: 0.0021\n",
      "Epoch 30, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "train_multistep_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                     num_epochs=50, patience=10, prediction_length=prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:00:00\n",
      "        Predicted Time  Predicted Traffic (Vehicles)\n",
      "0  2015-11-03 07:00:00                     14.365445\n",
      "1  2015-11-03 08:00:00                     13.884452\n",
      "2  2015-11-03 09:00:00                     13.273060\n",
      "3  2015-11-03 10:00:00                     12.776850\n",
      "4  2015-11-03 11:00:00                     12.468714\n",
      "5  2015-11-03 12:00:00                     12.187276\n",
      "6  2015-11-03 13:00:00                     11.871385\n",
      "7  2015-11-03 14:00:00                     11.457310\n",
      "8  2015-11-03 15:00:00                     10.917954\n",
      "9  2015-11-03 16:00:00                     10.190218\n",
      "10 2015-11-03 17:00:00                      9.318969\n",
      "11 2015-11-03 18:00:00                      8.423333\n",
      "12 2015-11-03 19:00:00                      7.703674\n",
      "13 2015-11-03 20:00:00                      7.228572\n",
      "14 2015-11-03 21:00:00                      6.988348\n",
      "15 2015-11-03 22:00:00                      6.991938\n",
      "16 2015-11-03 23:00:00                      7.277221\n",
      "17 2015-11-04 00:00:00                      7.877162\n",
      "18 2015-11-04 01:00:00                      8.796104\n",
      "19 2015-11-04 02:00:00                      9.864674\n",
      "20 2015-11-04 03:00:00                     10.701079\n",
      "21 2015-11-04 04:00:00                     11.160044\n",
      "22 2015-11-04 05:00:00                     11.277670\n",
      "23 2015-11-04 06:00:00                     11.271133\n"
     ]
    }
   ],
   "source": [
    "latest_time = pd.to_datetime(\"2015-11-03 07:00:00\")\n",
    "num_hours = 24\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "predictions = predict_future_traffic(model, latest_time, num_hours, scaler_dict)\n",
    "\n",
    "# Create prediction DataFrame\n",
    "predicted_times = [latest_time + timedelta(hours=i) for i in range(num_hours)]\n",
    "predicted_traffic_df = pd.DataFrame({\n",
    "    'Predicted Time': predicted_times,\n",
    "    'Predicted Traffic (Vehicles)': predictions\n",
    "})\n",
    "\n",
    "print(predicted_traffic_df)\n",
    "predicted_traffic_df.to_csv('predicted_traffic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Evaluation:\n",
      "Threshold is 0.03, which corresponds to 5 car(s) uncertainty\n",
      "Predicted values within this uncertainty are considered correct in the calculation of accuracy\n",
      "Test Accuracy: 56.12%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56.11823139175437"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.03\n",
    "uncertainty = (scaler_dict['Vehicles'].inverse_transform([[threshold]]) - \n",
    "              scaler_dict['Vehicles'].inverse_transform([[0]]))[0][0]\n",
    "print(f\"\\nAccuracy Evaluation:\")\n",
    "print(f\"Threshold is {threshold}, which corresponds to {int(uncertainty)} car(s) uncertainty\")\n",
    "print(\"Predicted values within this uncertainty are considered correct in the calculation of accuracy\")\n",
    "accuracy(model, test_loader, threshold, prediction_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
