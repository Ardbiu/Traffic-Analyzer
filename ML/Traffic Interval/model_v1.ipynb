{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and sort them by time\n",
    "df = pd.read_csv(\"./Data/traffic.csv\")\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.sort_values(by=['DateTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Junction as a numerical feature\n",
    "junction_encoder = LabelEncoder()\n",
    "df['Junction_encoded'] = junction_encoder.fit_transform(df['Junction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-based features for better pattern recognization\n",
    "df['Hour'] = df['DateTime'].dt.hour\n",
    "df['DayOfWeek'] = df['DateTime'].dt.dayofweek\n",
    "df['Month'] = df['DateTime'].dt.month\n",
    "df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "scaler_dict = {}\n",
    "numerical_features = ['Vehicles', 'Hour', 'DayOfWeek', 'Month', 'Junction_encoded']\n",
    "for feature in numerical_features:\n",
    "    scaler = MinMaxScaler()\n",
    "    df[f'{feature}_normalized'] = scaler.fit_transform(df[[feature]])\n",
    "    scaler_dict[feature] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model with multi-step prediction\n",
    "class JunctionTrafficLSTM(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=32, num_layers=5, output_size=1):\n",
    "        super(JunctionTrafficLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x, future_steps=1, teacher_forcing_ratio=0.5):\n",
    "        batch_size = x.size(0)\n",
    "        outputs = []\n",
    "        lstm_out, (h, c) = self.lstm(x)\n",
    "        decoder_input = x[:, -1:, :]\n",
    "        \n",
    "        for i in range(future_steps):\n",
    "            # Run LSTM step\n",
    "            out, (h, c) = self.lstm(decoder_input, (h, c))\n",
    "            \n",
    "            # Process through\n",
    "            features = self.dropout(out[:, -1])\n",
    "            features = self.relu(self.fc1(features))\n",
    "            features = self.relu(self.fc2(features))\n",
    "            prediction = self.fc3(features)\n",
    "            \n",
    "            outputs.append(prediction)\n",
    "        \n",
    "            if self.training and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                decoder_input = x[:, i+1:i+2, :] if i+1 < x.size(1) else decoder_input\n",
    "            else:\n",
    "                next_input = decoder_input.clone()\n",
    "                next_input[:, 0, 0] = prediction.squeeze()\n",
    "                decoder_input = next_input\n",
    "        \n",
    "        return torch.stack(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multistep_sequences(data, input_seq_length, prediction_length):\n",
    "    feature_cols = [col for col in data.columns if '_normalized' in col]\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    # Group by junction to ensure sequences don't cross junction boundaries\n",
    "    for junction in data['Junction'].unique():\n",
    "        junction_data = data[data['Junction'] == junction].copy()\n",
    "        \n",
    "        for i in range(len(junction_data) - input_seq_length - prediction_length):\n",
    "            seq = junction_data[feature_cols].iloc[i:i+input_seq_length].values\n",
    "            target = junction_data['Vehicles_normalized'].iloc[i+input_seq_length:i+input_seq_length+prediction_length].values\n",
    "            \n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multistep_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=10, prediction_length=24):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Generate predictions\n",
    "            outputs = model(batch_X, future_steps=prediction_length)\n",
    "            \n",
    "            # Ensure outputs and batch_y have the same shape\n",
    "            outputs = outputs.squeeze()\n",
    "            if len(outputs.shape) == 1:\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            if len(batch_y.shape) == 1:\n",
    "                batch_y = batch_y.unsqueeze(0)\n",
    "\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            if outputs.size(1) > 1:\n",
    "                output_diff = outputs[:, 1:] - outputs[:, :-1]\n",
    "                target_diff = batch_y[:, 1:] - batch_y[:, :-1]\n",
    "                \n",
    "                min_length = min(output_diff.size(1), target_diff.size(1))\n",
    "                consistency_loss = criterion(\n",
    "                    output_diff[:, :min_length],\n",
    "                    target_diff[:, :min_length]\n",
    "                )\n",
    "                loss = loss + 0.1 * consistency_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X, future_steps=prediction_length)\n",
    "                \n",
    "                outputs = outputs.squeeze()\n",
    "                if len(outputs.shape) == 1:\n",
    "                    outputs = outputs.unsqueeze(0)\n",
    "                if len(batch_y.shape) == 1:\n",
    "                    batch_y = batch_y.unsqueeze(0)\n",
    "                    \n",
    "                val_loss += criterion(outputs, batch_y).item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_loader, threshold, prediction_length=24):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X, future_steps=prediction_length)\n",
    "            difference = torch.abs(outputs.squeeze() - batch_y)\n",
    "            correct += (difference <= threshold).sum().item()\n",
    "            total += batch_y.numel()\n",
    "    \n",
    "    accuracy_percentage = (correct / total) * 100\n",
    "    print(f\"Test Accuracy: {accuracy_percentage:.2f}%\")\n",
    "    return accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_traffic(model, latest_time, num_hours, scalers, junction, seq_length=10):\n",
    "    \"\"\"\n",
    "    Make predictions for a specific junction\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained LSTM model\n",
    "    - latest_time: datetime object for the starting point\n",
    "    - num_hours: number of time steps to predict\n",
    "    - scalers: dictionary of fitted scalers\n",
    "    - junction: junction identifier (e.g., \"J1\")\n",
    "    - seq_length: length of input sequence\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array of predictions or None if junction not found\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Filter data for specific junction\n",
    "    junction_data = df[df['Junction'] == junction].copy()\n",
    "    \n",
    "    if len(junction_data) < seq_length:\n",
    "        raise ValueError(f\"Not enough data points for junction {junction}. Need at least {seq_length} points.\")\n",
    "    \n",
    "    # Find closest time that has enough subsequent data points\n",
    "    valid_times = junction_data[junction_data.index <= len(junction_data) - seq_length]['DateTime']\n",
    "    #if len(valid_times) == 0:\n",
    "       # raise ValueError(f\"No valid time points found for junction {junction} with sequence length {seq_length}\")\n",
    "    \n",
    "    closest_time_idx = (valid_times - latest_time).abs().argmin()\n",
    "    time_diff = (junction_data.iloc[closest_time_idx]['DateTime'] - latest_time)\n",
    "    print(f\"Time difference from requested: {time_diff}\")\n",
    "    \n",
    "    # Get feature columns\n",
    "    feature_cols = [col for col in df.columns if '_normalized' in col]\n",
    "    input_seq = junction_data.iloc[closest_time_idx:closest_time_idx+seq_length][feature_cols].values\n",
    "    \n",
    "    if len(input_seq) < seq_length:\n",
    "        raise ValueError(f\"Could not get enough sequential data points for junction {junction}\")\n",
    "    \n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_seq, future_steps=num_hours)\n",
    "        predictions = predictions.squeeze().cpu().numpy()\n",
    "\n",
    "    # Inverse transform \n",
    "    predictions = scalers['Vehicles'].inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seq_length = 10\n",
    "prediction_length = 24  # 24 hours ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_multistep_sequences(df, seq_length, prediction_length)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "val_size = int(0.1 * len(X_train))\n",
    "X_val = X_train[-val_size:]\n",
    "y_val = y_train[-val_size:]\n",
    "X_train = X_train[:-val_size]\n",
    "y_train = y_train[:-val_size]\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JunctionTrafficLSTM().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0052, Val Loss: 0.0038\n",
      "Epoch 2, Train Loss: 0.0019, Val Loss: 0.0025\n",
      "Epoch 3, Train Loss: 0.0013, Val Loss: 0.0023\n",
      "Epoch 4, Train Loss: 0.0011, Val Loss: 0.0024\n",
      "Epoch 5, Train Loss: 0.0010, Val Loss: 0.0024\n",
      "Epoch 6, Train Loss: 0.0010, Val Loss: 0.0022\n",
      "Epoch 7, Train Loss: 0.0009, Val Loss: 0.0021\n",
      "Epoch 8, Train Loss: 0.0009, Val Loss: 0.0021\n",
      "Epoch 9, Train Loss: 0.0008, Val Loss: 0.0021\n",
      "Epoch 10, Train Loss: 0.0008, Val Loss: 0.0020\n",
      "Epoch 11, Train Loss: 0.0008, Val Loss: 0.0023\n",
      "Epoch 12, Train Loss: 0.0007, Val Loss: 0.0021\n",
      "Epoch 13, Train Loss: 0.0007, Val Loss: 0.0022\n",
      "Epoch 14, Train Loss: 0.0007, Val Loss: 0.0020\n",
      "Epoch 15, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 16, Train Loss: 0.0006, Val Loss: 0.0021\n",
      "Epoch 17, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 18, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 19, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 20, Train Loss: 0.0006, Val Loss: 0.0019\n",
      "Epoch 21, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 22, Train Loss: 0.0006, Val Loss: 0.0019\n",
      "Epoch 23, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 24, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 25, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 26, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 27, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 28, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Epoch 29, Train Loss: 0.0006, Val Loss: 0.0021\n",
      "Epoch 30, Train Loss: 0.0006, Val Loss: 0.0020\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "#train_multistep_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=10, prediction_length=prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference from requested: 0 days 00:00:00\n",
      "       Predicted Time  Predicted Traffic (Vehicles)  Junction\n",
      "0 2016-11-03 07:00:00                          65.0         1\n",
      "1 2016-11-06 07:00:00                          67.0         1\n",
      "2 2016-11-09 07:00:00                          70.0         1\n",
      "3 2016-11-12 07:00:00                          69.0         1\n",
      "4 2016-11-15 07:00:00                          66.0         1\n"
     ]
    }
   ],
   "source": [
    "latest_time = pd.to_datetime(\"2016-11-03 07:00:00\")\n",
    "junction = 1\n",
    "count = 5\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_saved_model.pth'))\n",
    "predictions = predict_future_traffic(model, latest_time, count, scaler_dict, junction)\n",
    "\n",
    "# Change timedelta for different prediction interval\n",
    "\n",
    "predicted_times = [latest_time + 3* timedelta(days=i) for i in range(count)]\n",
    "predicted_traffic_df = pd.DataFrame({\n",
    "    'Predicted Time': predicted_times,\n",
    "    'Predicted Traffic (Vehicles)': (predictions)//1,\n",
    "    'Junction': junction\n",
    "})\n",
    "\n",
    "print(predicted_traffic_df)\n",
    "predicted_traffic_df.to_csv('predicted_traffic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Evaluation:\n",
      "Threshold is 0.03, which corresponds to 5 car(s) uncertainty\n",
      "Predicted values within this uncertainty are considered correct in the calculation of accuracy\n",
      "Test Accuracy: 56.12%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56.11823139175437"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.03\n",
    "uncertainty = (scaler_dict['Vehicles'].inverse_transform([[threshold]]) - \n",
    "              scaler_dict['Vehicles'].inverse_transform([[0]]))[0][0]\n",
    "print(f\"\\nAccuracy Evaluation:\")\n",
    "print(f\"Threshold is {threshold}, which corresponds to {int(uncertainty)} car(s) uncertainty\")\n",
    "print(\"Predicted values within this uncertainty are considered correct in the calculation of accuracy\")\n",
    "accuracy(model, test_loader, threshold, prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
